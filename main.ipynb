{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os.path\n",
    "\n",
    "def download_sound(word, dirpath=\"public/sounds\", slow=False):\n",
    "    temp_file = f\"{dirpath}/{word}.mp3\"\n",
    "    try:\n",
    "        if not os.path.isfile(temp_file):\n",
    "            # Create a gTTS object with Chinese language\n",
    "            tts = gTTS(text=word, lang='zh-TW', slow=slow)\n",
    "            # Save the audio file temporarily\n",
    "            tts.save(temp_file)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "download_sound(\"號\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def extract_stroke_order(character=\"天\", dirpath=\"public\"):\n",
    "    if len(character) > 1:\n",
    "        for c in character: extract_stroke_order(c)\n",
    "        return\n",
    "    elif len(character) == 0: return\n",
    "    \n",
    "    animation_path = f\"{dirpath}/animation/{character}.gif\"\n",
    "    stroke_path = f\"{dirpath}/stroke/{character}.png\"\n",
    "    \n",
    "    if os.path.isfile(animation_path) and os.path.isfile(stroke_path):\n",
    "        return []\n",
    "    \n",
    "    base_url = \"https://www.strokeorder.com\"\n",
    "    url = f\"{base_url}/chinese/{character}\"\n",
    "    try:\n",
    "        # Fetch the webpage content\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all divs with the specified class\n",
    "        target_divs = soup.find_all('div', class_='stroke-article-content')\n",
    "\n",
    "        # Extract image sources from these divs\n",
    "        image_sources = []\n",
    "        for div in target_divs:\n",
    "            images = div.find_all('img')\n",
    "            for img in images:\n",
    "                src = img.get('src')\n",
    "                if src:  # Only add if src exists\n",
    "                    image_sources.append(src)\n",
    "\n",
    "        if image_sources:\n",
    "            for src in image_sources:\n",
    "                if src.startswith(\"/assets/bishun/animation/\"):\n",
    "                    try:\n",
    "                        absolute_url = urljoin(base_url, src)\n",
    "                        img_response = requests.get(absolute_url, headers=headers)\n",
    "                        img_response.raise_for_status()\n",
    "                        \n",
    "                        with open(animation_path, \"wb\") as f:\n",
    "                            f.write(img_response.content)\n",
    "                    except Exception as e: print(str(e))\n",
    "                elif src.startswith(\"/assets/bishun/stroke/\"):\n",
    "                    try:\n",
    "                        absolute_url = urljoin(base_url, src)\n",
    "                        img_response = requests.get(absolute_url, headers=headers)\n",
    "                        img_response.raise_for_status()\n",
    "                        \n",
    "                        with open(stroke_path, \"wb\") as f:\n",
    "                            f.write(img_response.content)\n",
    "                    except: pass\n",
    "            \n",
    "        return image_sources\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the webpage: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "    \n",
    "extract_stroke_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def import_decks(filepath=\"decks.txt\"):\n",
    "    decks, _decks = {\"decks\": []}, {}\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f.read().split(\"\\n\"):\n",
    "            if not line.startswith(\"#\"):\n",
    "                segments = line.split(\"\\t\")\n",
    "                if len(segments) == 5:\n",
    "                    try:\n",
    "                        download_sound(segments[0])\n",
    "                        extract_stroke_order(segments[4].strip())\n",
    "                        \n",
    "                        if not os.path.os.path.isfile(f\"public/sounds/{segments[0].strip()}.mp3\"):\n",
    "                            continue\n",
    "                        \n",
    "                        is_complete = True\n",
    "                        for char in segments[4].strip():\n",
    "                            if not os.path.os.path.isfile(f\"public/stroke/{char}.png\"):\n",
    "                                is_complete = False\n",
    "                            if not os.path.os.path.isfile(f\"public/animation/{char}.gif\"):\n",
    "                                is_complete = False\n",
    "                        if not is_complete: continue\n",
    "                        \n",
    "                        chars = [c for c in segments[4].strip()]\n",
    "                        strokes = [f\"stroke/{c}.png\" for c in chars]\n",
    "                        animations = [f\"animation/{c}.gif\" for c in chars]\n",
    "                        \n",
    "                        if segments[2].strip() not in _decks: \n",
    "                            _decks[segments[2].strip()] = []\n",
    "                            \n",
    "                        _decks[segments[2].strip()].append({\n",
    "                            \"mp3\": f\"sounds/{segments[0].strip()}.mp3\",\n",
    "                            \"word\": segments[0].strip(),\n",
    "                            \"means\": segments[1].strip(),\n",
    "                            \"pinyin\": segments[3].strip(),\n",
    "                            \"stroke\": strokes,\n",
    "                            \"animation\": animations\n",
    "                        })\n",
    "                    except: print(f\"Error {line}\")\n",
    "                else: print(line)\n",
    "    for k, v in _decks.items():\n",
    "        decks[\"decks\"].append({\n",
    "            \"name\": k,\n",
    "            \"items\": v\n",
    "        })\n",
    "    with open(\"public/decks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(decks, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "import_decks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
